{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Vectorización\n"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"PUbfVnzIIoMj"},"outputs":[],"source":["def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"]},{"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"RIO7b8GjAC17"},"outputs":[],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"]},{"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"3ZqTOZzDI7uv"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'que', 'muchas', 'dia', 'gracias', 'de', 'el', 'hoy', 'es', 'martes'}\n"]}],"source":["documentos = [documento.split() for documento in corpus]\n","vocabulario =set()\n","for documento in documentos:\n","    vocabulario.update(documento)\n","print (vocabulario)"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[['que', 'dia', 'es', 'hoy'], ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'], ['martes', 'muchas', 'gracias']]\n"]}],"source":["print (documentos)"]},{"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"Os0AAQo6I6Z1"},"outputs":[{"data":{"text/plain":["array([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0]])"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["dict_vocab={palabra:i for i,palabra in enumerate(vocabulario)}\n","one_hot_matrix = np.zeros((len(documentos), len(vocabulario)), dtype=int)\n","one_hot_matrix\n"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"data":{"text/plain":["{'que': 0,\n"," 'muchas': 1,\n"," 'dia': 2,\n"," 'gracias': 3,\n"," 'de': 4,\n"," 'el': 5,\n"," 'hoy': 6,\n"," 'es': 7,\n"," 'martes': 8}"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["dict_vocab"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Documento 0: [1 0 1 0 0 0 1 1 0]\n","Documento 1: [0 0 1 0 1 1 1 1 1]\n","Documento 2: [0 1 0 1 0 0 0 0 1]\n"]}],"source":["for n_doc,documento in enumerate(documentos):\n","    for palabra in documento:\n","        one_hot_matrix[n_doc,dict_vocab[palabra]]=1\n","print (\"Documento 0:\",one_hot_matrix[0,:])\n","print (\"Documento 1:\",one_hot_matrix[1,:])\n","print (\"Documento 2:\",one_hot_matrix[2,:])"]},{"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"yqij_7eHJbUi"},"outputs":[{"name":"stdout","output_type":"stream","text":["Documento 0: [1 0 1 0 0 0 1 1 0]\n","Documento 1: [0 0 1 0 1 1 1 1 2]\n","Documento 2: [0 1 0 1 0 0 0 0 1]\n"]}],"source":["frec_matrix= np.zeros((len(documentos), len(vocabulario)), dtype=int)\n","for n_doc,documento in enumerate(documentos):\n","    for palabra in documento:\n","        frec_matrix[n_doc,dict_vocab[palabra]]+=1\n","print (\"Documento 0:\",frec_matrix[0,:])\n","print (\"Documento 1:\",frec_matrix[1,:])\n","print (\"Documento 2:\",frec_matrix[2,:])"]},{"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Data una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"waG_oWtpJjRw"},"outputs":[{"name":"stdout","output_type":"stream","text":["Palabras en vocabulario:\n","\t dict_keys(['que', 'muchas', 'dia', 'gracias', 'de', 'el', 'hoy', 'es', 'martes'])\n","Cantidad apariciones: [1. 1. 2. 1. 1. 1. 2. 2. 3.]\n","Valor idf: [3.  3.  1.5 3.  3.  3.  1.5 1.5 1. ]\n"]}],"source":["tf_idf_matrix= np.zeros((len(documentos), len(vocabulario)), dtype=float)\n","cant_doc=len(documentos)\n","idf= np.zeros (len(vocabulario),dtype=float)\n","for j,documento in enumerate(documentos):\n","    for k,palabra in enumerate(documento):\n","            idf[dict_vocab[palabra]]=idf[dict_vocab[palabra]]+1\n","print(\"Palabras en vocabulario:\\n\\t\", dict_vocab.keys())\n","print (\"Cantidad apariciones:\",idf)\n","for i in range(len(idf)):\n","    idf[i]= cant_doc/idf[i]\n","print(\"Valor idf:\", idf)\n","\n"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"data":{"text/plain":["array([[3. , 0. , 1.5, 0. , 0. , 0. , 1.5, 1.5, 0. ],\n","       [0. , 0. , 1.5, 0. , 3. , 3. , 1.5, 1.5, 2. ],\n","       [0. , 3. , 0. , 3. , 0. , 0. , 0. , 0. , 1. ]])"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["for i in range(tf_idf_matrix.shape[0]):\n","    for j in range(tf_idf_matrix.shape[1]):\n","        tf_idf_matrix[i,j]=frec_matrix[i,j]*idf[j]\n","tf_idf_matrix"]},{"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":58,"metadata":{"id":"CZdiop6IJpZN"},"outputs":[],"source":["def similitud_coseno(vector1, vector2):\n","    dot_product = np.dot(vector1, vector2)\n","    norm_vector1 = np.linalg.norm(vector1)\n","    norm_vector2 = np.linalg.norm(vector2)\n","    return dot_product / (norm_vector1 * norm_vector2)\n","def ordenar_documentos_por_similitud(corpus, indice_referencia):    \n","    \n","    similitudes = []\n","    documento_referencia = frec_matrix[indice_referencia]\n","    for documento in frec_matrix:\n","        similitud = similitud_coseno(documento_referencia, documento)\n","        similitudes.append(similitud)\n","    \n","    # Obtener los índices de los documentos ordenados por similitud (excluyendo el documento de referencia)\n","    indices_ordenados = np.argsort(similitudes)[::-1][1:]\n","    \n","    # Obtener los documentos ordenados por similitud\n","    documentos_ordenados = [corpus[i] for i in indices_ordenados]\n","    \n","    return documentos_ordenados"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Doc. de referencia: martes muchas gracias\n","Documentos ordenados de mas a menos parecidos:\n","\t Documento 1: martes el dia de hoy es martes\n","\t Documento 2: que dia es hoy\n"]}],"source":["indice_referencia = 2\n","\n","documentos_ordenados = ordenar_documentos_por_similitud(corpus, indice_referencia)\n","\n","# Imprimir los documentos ordenados por similitud\n","print(\"Doc. de referencia:\", corpus[indice_referencia])\n","print(\"Documentos ordenados de mas a menos parecidos:\")\n","for i, documento in enumerate(documentos_ordenados, start=1):\n","    print(f\"\\t Documento {i}: {documento}\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO5fRYTpympAwJSVbric6dW","collapsed_sections":[],"name":"1a - word2vec.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
